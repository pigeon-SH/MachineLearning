{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatDogImageClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqElXMDfN0U4J/1hxnd6Zz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import and mount drive\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNFJ-SS9RS8w",
        "outputId": "dae1de93-c0d8-4c7e-bce5-a3cf056e85a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load images\n",
        "catimages = []\n",
        "catimages_num = 393\n",
        "for i in range(catimages_num):\n",
        "    img_file = '/gdrive/MyDrive/CS/Image Classifier/ImageCat/cat' + str(i) + '.jpg'\n",
        "    img = cv2.imread(img_file)\n",
        "\n",
        "    catimages.append(img)\n",
        "\n",
        "dogimages = []\n",
        "dogimages_num = 401\n",
        "for i in range(dogimages_num):\n",
        "    img_file = '/gdrive/MyDrive/CS/Image Classifier/ImageDog/dog' + str(i) + '.jpg'\n",
        "    img = cv2.imread(img_file)\n",
        "\n",
        "    dogimages.append(img)\n",
        "imgHeight = len(catimages[0][0])\n",
        "imgChannel = len(catimages[0][0][0])"
      ],
      "metadata": {
        "id": "nSnKA9QH8A1Q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# resize images to 32 * 32 pixels\n",
        "for i in range(catimages_num):\n",
        "    catimages[i] = cv2.resize(catimages[i], dsize=(32, 32), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "cv2_imshow(catimages[0])\n",
        "print()\n",
        "\n",
        "for i in range(dogimages_num):\n",
        "    dogimages[i] = cv2.resize(dogimages[i], dsize=(32, 32), interpolation=cv2.INTER_AREA)\n",
        "cv2_imshow(dogimages[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "sHA0c9SH7l1g",
        "outputId": "4ea16803-5427-49a9-9c4d-ad5451fa9f0b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F029A7BDA10>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F0299F47350>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make trainImages, trainLabel, testImage, testLabel\n",
        "#Label 0: cat, 1: dog\n",
        "#transpose version\n",
        "cattest_num = catimages_num % 100\n",
        "dogtest_num = dogimages_num % 100 + 50\n",
        "cattrain_num = catimages_num - cattest_num\n",
        "dogtrain_num = dogimages_num - dogtest_num\n",
        "\n",
        "train_num = cattrain_num + dogtrain_num\n",
        "test_num = catimages_num + dogimages_num - train_num\n",
        "\n",
        "trainImages = np.zeros((train_num, imgChannel, 32, 32))\n",
        "testImages = np.zeros((test_num, imgChannel, 32, 32))\n",
        "trainLabel = np.zeros((train_num, 2))\n",
        "testLabel = np.zeros((test_num, 2))\n",
        "\n",
        "for i in range(cattrain_num):\n",
        "    trainImages[i] = catimages[i].T\n",
        "    trainLabel[i][0] = 1\n",
        "for i in range(dogtrain_num):\n",
        "    trainImages[i + cattrain_num] = dogimages[i].T\n",
        "    trainLabel[i + cattrain_num][1] = 1\n",
        "\n",
        "for i in range(cattest_num):\n",
        "    testImages[i] = catimages[i + cattrain_num].T\n",
        "    testLabel[i][0] = 1\n",
        "for i in range(dogtest_num):\n",
        "    testImages[i + cattest_num] = dogimages[i + dogtrain_num].T\n",
        "    testLabel[i + cattest_num][1] = 1\n",
        "\n",
        "print(\"trainImages shape\", trainImages.shape)\n",
        "print(\"testImages shape\", testImages.shape)\n",
        "print(\"trainLabel shape\", trainLabel.shape)\n",
        "print(\"testLabel shape\", testLabel.shape)\n",
        "\n",
        "#shuffle\n",
        "randomidx = np.arange(len(trainLabel))\n",
        "trainImages = trainImages[randomidx]\n",
        "trainLabel = trainLabel[randomidx]\n",
        "\n",
        "randomidx = np.arange(len(testLabel))\n",
        "testImages = testImages[randomidx]\n",
        "testLabel = testLabel[randomidx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25j5XmT0IqyE",
        "outputId": "f440e1df-a3fb-4cc8-de0c-7f0858c566d1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainImages shape (650, 3, 32, 32)\n",
            "testImages shape (144, 3, 32, 32)\n",
            "trainLabel shape (650, 2)\n",
            "testLabel shape (144, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN with pytorch module"
      ],
      "metadata": {
        "id": "SRnaSQIbRQQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import ReLU\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_channel, input_size, class_num):\n",
        "        super(CNN,self).__init__()\n",
        "        self.convSeq = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, 12, 3),    #(n*n*input_channel) => ((n-2)*(n-2)*12)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(12, 12, 3),   #((n-2)*(n-2)*12) => ((n-4)*(n-4)*12)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),    #((n-4)*(n-4)*12) => ((n-4)/2)*((n-4)/2)*12\n",
        "            nn.Conv2d(12, 24, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(24, 24, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "            #if n=32, output shape of convSeq is (batch_size, 5, 5, 24)\n",
        "        )\n",
        "        afterConvSize = (((input_size - 4) // 2) - 4) // 2\n",
        "        self.FCSeq = nn.Sequential(\n",
        "            nn.Linear(afterConvSize * afterConvSize * 24 , 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, 600),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(600, 800),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(800, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, class_num),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def flatten(self, input):\n",
        "        return torch.flatten(input, 1)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        x = self.convSeq(input)\n",
        "        x = self.flatten(x)\n",
        "        x = self.FCSeq(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "NVw-howRUr81"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('device_check:',device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu20T1O5JBMD",
        "outputId": "2895bdf9-e8df-483a-9565-5c2f4c4bbd57"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device_check: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train Image\n",
        "EPOCHS = 1000\n",
        "batch_size = 60\n",
        "model = CNN(imgChannel, 32, 2)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    for batch_num in range(len(trainImages) // batch_size + 1):\n",
        "        if batch_num != len(trainImages) // batch_size:\n",
        "            batchImage = trainImages[batch_num * batch_size : (batch_num + 1) * batch_size, :, :, :]\n",
        "            batchLabel = trainLabel[batch_num * batch_size : (batch_num + 1) * batch_size, :]\n",
        "        else:\n",
        "            batchImage = trainImages[batch_num * batch_size :, :, :, :]\n",
        "            batchLabel = trainLabel[batch_num * batch_size :, :]\n",
        "        \n",
        "        batchImage = torch.tensor(batchImage, dtype=torch.float32, device=device)\n",
        "        batchLabel = torch.tensor(batchLabel, dtype=torch.float32, device=device)\n",
        "\n",
        "        pred = model(batchImage)\n",
        "        loss = loss_fn(pred, batchLabel)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"i: {:4d} || loss: {:.3f}\".format(i, loss))\n"
      ],
      "metadata": {
        "id": "8IGedkyy8dmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2065d7d3-e85c-4942-8828-9af6334ed23b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:    0 || loss: 1.313\n",
            "i:  100 || loss: 1.313\n",
            "i:  200 || loss: 1.313\n",
            "i:  300 || loss: 1.313\n",
            "i:  400 || loss: 1.313\n",
            "i:  500 || loss: 1.313\n",
            "i:  600 || loss: 1.313\n",
            "i:  700 || loss: 1.313\n",
            "i:  800 || loss: 1.313\n",
            "i:  900 || loss: 1.313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "testX = torch.tensor(testImages, dtype=torch.float32, device=device)\n",
        "testY = torch.tensor(testLabel, dtype=torch.float32, device=device)\n",
        "with torch.no_grad():\n",
        "    prediction = model(testX)\n",
        "\n",
        "    accuracy = np.equal(prediction.cpu().numpy(), testY.cpu().numpy()).mean()\n",
        "\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "0v4dHdHTHl5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819a675e-560d-4327-eb45-8337c8b9affa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fjqDYjs2TvPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not use this cell: image size 600 * 636 is too large, it causes RAM overflow\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "# all images have same Height, same Channels but various Width\n",
        "# if Width is smaller than 600, put values in middle-Width, and fill rest area with 0\n",
        "# all images size: 600*imgHeight*imgChannel\n",
        "imgWidth = 600\n",
        "for i in range(catimages_num):\n",
        "    if len(catimages[i]) < imgWidth:\n",
        "        topBlanks = (imgWidth - len(catimages[i])) // 2\n",
        "        bottomBlanks = imgWidth - topBlanks - len(catimages[i])\n",
        "\n",
        "        resizedImg = np.zeros((imgWidth, imgHeight, imgChannel))\n",
        "        for w in range(len(catimages[i])):\n",
        "            resizedImg[w + topBlanks] = catimages[i][w]\n",
        "        catimages[i] = resizedImg\n",
        "cv2_imshow(catimages[0])\n",
        "print()\n",
        "\n",
        "for i in range(dogimages_num):\n",
        "    if len(dogimages[i]) < imgWidth:\n",
        "        topBlanks = (imgWidth - len(dogimages[i])) // 2\n",
        "        bottomBlanks = imgWidth - topBlanks - len(dogimages[i])\n",
        "\n",
        "        resizedImg = np.zeros((imgWidth, imgHeight, imgChannel))\n",
        "        for w in range(len(dogimages[i])):\n",
        "            resizedImg[w + topBlanks] = dogimages[i][w]\n",
        "        dogimages[i] = resizedImg\n",
        "cv2_imshow(dogimages[0])"
      ],
      "metadata": {
        "id": "6Ax7ul_zSjwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do not use this cell: size should be (batch_size, channel, width, height) and so needs transpose\n",
        "#make trainImages, trainLabel, testImage, testLabel\n",
        "#Label 0: cat, 1: dog\n",
        "cattest_num = catimages_num % 100\n",
        "dogtest_num = dogimages_num % 100\n",
        "cattrain_num = catimages_num - cattest_num\n",
        "dogtrain_num = dogimages_num - dogtest_num\n",
        "\n",
        "train_num = cattrain_num + dogtrain_num\n",
        "test_num = catimages_num + dogimages_num - train_num\n",
        "\n",
        "trainImages = np.zeros((train_num, 32, 32, imgChannel))\n",
        "testImages = np.zeros((test_num, 32, 32, imgChannel))\n",
        "trainLabel = np.zeros((train_num, 2))\n",
        "testLabel = np.zeros((test_num, 2))\n",
        "\n",
        "for i in range(cattrain_num):\n",
        "    trainImages[i] = catimages[i]\n",
        "    trainLabel[i][0] = 1\n",
        "for i in range(dogtrain_num):\n",
        "    trainImages[i + cattrain_num] = dogimages[i]\n",
        "    trainLabel[i + cattrain_num][1] = 1\n",
        "\n",
        "for i in range(cattest_num):\n",
        "    testImages[i] = catimages[i + cattrain_num]\n",
        "    testLabel[i][0] = 1\n",
        "for i in range(dogtest_num):\n",
        "    testImages[i + cattest_num] = dogimages[i + dogtrain_num]\n",
        "    testLabel[i + cattest_num][1] = 1\n",
        "\n",
        "print(\"trainImages shape\", trainImages.shape)\n",
        "print(\"testImages shape\", testImages.shape)\n",
        "print(\"trainLabel shape\", trainLabel.shape)\n",
        "print(\"testLabel shape\", testLabel.shape)\n",
        "\n",
        "#shuffle\n",
        "randomidx = np.arange(len(trainLabel))\n",
        "trainImages = trainImages[randomidx]\n",
        "trainLabel = trainLabel[randomidx]\n",
        "\n",
        "randomidx = np.arange(len(testLabel))\n",
        "testImages = testImages[randomidx]\n",
        "testLabel = testLabel[randomidx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPkKwV1nt5JM",
        "outputId": "c885ba3c-2caf-4dc8-df33-9a728516117d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainImages shape (700, 32, 32, 3)\n",
            "testImages shape (94, 32, 32, 3)\n",
            "trainLabel shape (700, 2)\n",
            "testLabel shape (94, 2)\n"
          ]
        }
      ]
    }
  ]
}